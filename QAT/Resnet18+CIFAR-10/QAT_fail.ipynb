{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.quantization import fuse_modules\n",
    "from torch.nn.quantized import FloatFunctional\n",
    "from torch import Tensor\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "from resnet import resnet18\n",
    "\n",
    "# Set up warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\n",
    "    action='ignore',\n",
    "    category=DeprecationWarning,\n",
    "    module=r'.*'\n",
    ")\n",
    "warnings.filterwarnings(\n",
    "    action='default',\n",
    "    module=r'torch.ao.quantization'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seeds(random_seed=0):\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(random_seed)\n",
    "    random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataloader(num_workers=8, train_batch_size=128, eval_batch_size=256):\n",
    "\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "        transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "    ])\n",
    "\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "        transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "    ])\n",
    "\n",
    "    train_set = torchvision.datasets.CIFAR10(root=\"data\", train=True, download=True, transform=train_transform) \n",
    "    # We will use test set for validation and test in this project.\n",
    "    # Do not use test set for validation in practice!\n",
    "    test_set = torchvision.datasets.CIFAR10(root=\"data\", train=False, download=True, transform=test_transform)\n",
    "\n",
    "    train_sampler = torch.utils.data.RandomSampler(train_set)\n",
    "    test_sampler = torch.utils.data.SequentialSampler(test_set)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset=train_set, batch_size=train_batch_size,\n",
    "        sampler=train_sampler, num_workers=num_workers)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        dataset=test_set, batch_size=eval_batch_size,\n",
    "        sampler=test_sampler, num_workers=num_workers)\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device, criterion=None):\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    running_loss = 0\n",
    "    running_corrects = 0\n",
    "\n",
    "    for inputs, labels in test_loader:\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        if criterion is not None:\n",
    "            loss = criterion(outputs, labels).item()\n",
    "        else:\n",
    "            loss = 0\n",
    "\n",
    "        # statistics\n",
    "        running_loss += loss * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    eval_loss = running_loss / len(test_loader.dataset)\n",
    "    eval_accuracy = running_corrects / len(test_loader.dataset)\n",
    "\n",
    "    return eval_loss, eval_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, test_loader, device, learning_rate=1e-1, num_epochs=200):\n",
    "\n",
    "    # The training configurations were not carefully selected.\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    # It seems that SGD optimizer is better than Adam optimizer for ResNet18 training on CIFAR10.\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=1e-4)\n",
    "    # scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=500)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[100, 150], gamma=0.1, last_epoch=-1)\n",
    "    # optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    eval_loss, eval_accuracy = evaluate_model(model=model, test_loader=test_loader, device=device, criterion=criterion)\n",
    "    print(\"Epoch: {:02d} Eval Loss: {:.3f} Eval Acc: {:.3f}\".format(-1, eval_loss, eval_accuracy))\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # Training\n",
    "        model.train()\n",
    "\n",
    "        running_loss = 0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "        train_accuracy = running_corrects / len(train_loader.dataset)\n",
    "\n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        eval_loss, eval_accuracy = evaluate_model(model=model, test_loader=test_loader, device=device, criterion=criterion)\n",
    "\n",
    "        # Set learning rate scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "        print(\"Epoch: {:03d} Train Loss: {:.3f} Train Acc: {:.3f} Eval Loss: {:.3f} Eval Acc: {:.3f}\".format(epoch, train_loss, train_accuracy, eval_loss, eval_accuracy))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate_model(model, loader, device=torch.device(\"cpu:0\")):\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    for inputs, labels in loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        _ = model(inputs)\n",
    "\n",
    "def measure_inference_latency(model,\n",
    "                              device,\n",
    "                              input_size=(1, 3, 32, 32),\n",
    "                              num_samples=100,\n",
    "                              num_warmups=10):\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    x = torch.rand(size=input_size).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_warmups):\n",
    "            _ = model(x)\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        start_time = time.time()\n",
    "        for _ in range(num_samples):\n",
    "            _ = model(x)\n",
    "            torch.cuda.synchronize()\n",
    "        end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_time_ave = elapsed_time / num_samples\n",
    "\n",
    "    return elapsed_time_ave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_dir, model_filename):\n",
    "\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    model_filepath = os.path.join(model_dir, model_filename)\n",
    "    torch.save(model.state_dict(), model_filepath)\n",
    "\n",
    "def load_model(model, model_filepath, device):\n",
    "\n",
    "    model.load_state_dict(torch.load(model_filepath, map_location=device))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_torchscript_model(model, model_dir, model_filename):\n",
    "\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    model_filepath = os.path.join(model_dir, model_filename)\n",
    "    torch.jit.save(torch.jit.script(model), model_filepath)\n",
    "    \n",
    "def load_torchscript_model(model_filepath, device):\n",
    "\n",
    "    model = torch.jit.load(model_filepath, map_location=device)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(num_classes=10):\n",
    "\n",
    "    model = resnet18(num_classes=num_classes, pretrained=False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantizedResNet18(nn.Module):\n",
    "    def __init__(self, model_fp32):\n",
    "        super(QuantizedResNet18, self).__init__()\n",
    "        # QuantStub converts tensors from floating point to quantized.\n",
    "        # This will only be used for inputs.\n",
    "        self.quant = torch.ao.quantization.QuantStub()\n",
    "        # DeQuantStub converts tensors from quantized to floating point.\n",
    "        # This will only be used for outputs.\n",
    "        self.dequant = torch.ao.quantization.DeQuantStub()\n",
    "        # FP32 model\n",
    "        self.model_fp32 = model_fp32\n",
    "        \n",
    "    def model_fuse(self):\n",
    "        # ③ layer fusion을 적용합니다.\n",
    "        # Fuse the model in place rather manually.\n",
    "        self.model_fp32 = torch.ao.quantization.fuse_modules_qat(self.model_fp32, [[\"conv1\", \"bn1\"]], inplace=True)\n",
    "        for module_name, module in self.model_fp32.named_children():\n",
    "            if \"layer\" in module_name:\n",
    "                for basic_block_name, basic_block in module.named_children():\n",
    "                    torch.ao.quantization.fuse_modules_qat(basic_block, [[\"conv1\", \"bn1\"], [\"conv2\", \"bn2\"]], inplace=True)\n",
    "                    for sub_block_name, sub_block in basic_block.named_children():\n",
    "                        if sub_block_name == \"downsample\":\n",
    "                            torch.ao.quantization.fuse_modules_qat(sub_block, [[\"0\", \"1\"]], inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # manually specify where tensors will be converted from floating\n",
    "        # point to quantized in the quantized model\n",
    "        x = self.quant(x)\n",
    "        x = self.model_fp32(x)\n",
    "        # manually specify where tensors will be converted from quantized\n",
    "        # to floating point in the quantized model\n",
    "        x = self.dequant(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_equivalence(model_1, model_2, device, rtol=1e-05, atol=1e-08, num_tests=100, input_size=(1,3,32,32)):\n",
    "\n",
    "    model_1.to(device)\n",
    "    model_2.to(device)\n",
    "\n",
    "    for _ in range(num_tests):\n",
    "        x = torch.rand(size=input_size).to(device)\n",
    "        y1 = model_1(x).detach().cpu().numpy()\n",
    "        y2 = model_2(x).detach().cpu().numpy()\n",
    "        \n",
    "        \n",
    "        if np.allclose(a=y1, b=y2, rtol=rtol, atol=atol, equal_nan=False) == False:\n",
    "            print(\"Model equivalence test sample failed: \")\n",
    "            print(y1)\n",
    "            print(y2)\n",
    "            return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 0\n",
    "num_classes = 10\n",
    "cuda_device = torch.device(\"cuda:0\")\n",
    "cpu_device = torch.device(\"cpu:0\")\n",
    "model_dir = \"saved_models\"\n",
    "model_filename = \"resnet18_cifar10.pt\"\n",
    "quantized_model_filename = \"resnet18_quantized_cifar10.pt\"\n",
    "model_filepath = os.path.join(model_dir, model_filename)\n",
    "quantized_model_filepath = os.path.join(model_dir, quantized_model_filename)\n",
    "set_random_seeds(random_seed=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader = prepare_dataloader(num_workers=8, train_batch_size=128, eval_batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model...\n"
     ]
    }
   ],
   "source": [
    "# Create an untrained model.\n",
    "model = create_model(num_classes=num_classes)\n",
    "\n",
    "print(\"Training Model...\")\n",
    "# model = train_model(model=model, train_loader=train_loader, test_loader=test_loader, device=cuda_device, learning_rate=1e-1, num_epochs=1)\n",
    "\n",
    "# Save model.\n",
    "save_model(model=model, model_dir=model_dir, model_filename=model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(model=create_model(num_classes=num_classes), model_filepath=model_filepath, device=cuda_device)\n",
    "\n",
    "# ② 모델을 CPU 상태로 두고 학습 모드로 변환합니다. (model.train())\n",
    "model.to(cpu_device)\n",
    "\n",
    "# Make a copy of the model for layer fusion\n",
    "fused_model = QuantizableResNet18(10)\n",
    "fused_model.load_state_dict(model.state_dict())\n",
    "fused_model.fuse_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuantizableResNet(\n",
       "  (conv1): ConvBnReLU2d(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (bn1): Identity()\n",
       "  (relu): Identity()\n",
       "  (layer1): Sequential(\n",
       "    (0): QuantizableBasicBlock(\n",
       "      (conv1): ConvBn2d(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (bn1): Identity()\n",
       "      (conv2): ConvBn2d(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (shortcut): Sequential()\n",
       "      (float_functional): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): QuantizableBasicBlock(\n",
       "      (conv1): ConvBn2d(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (bn1): Identity()\n",
       "      (conv2): ConvBn2d(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (shortcut): Sequential()\n",
       "      (float_functional): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): QuantizableBasicBlock(\n",
       "      (conv1): ConvBn2d(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (bn1): Identity()\n",
       "      (conv2): ConvBn2d(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (float_functional): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): QuantizableBasicBlock(\n",
       "      (conv1): ConvBn2d(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (bn1): Identity()\n",
       "      (conv2): ConvBn2d(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (shortcut): Sequential()\n",
       "      (float_functional): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): QuantizableBasicBlock(\n",
       "      (conv1): ConvBn2d(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (bn1): Identity()\n",
       "      (conv2): ConvBn2d(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (float_functional): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): QuantizableBasicBlock(\n",
       "      (conv1): ConvBn2d(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (bn1): Identity()\n",
       "      (conv2): ConvBn2d(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (shortcut): Sequential()\n",
       "      (float_functional): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): QuantizableBasicBlock(\n",
       "      (conv1): ConvBn2d(\n",
       "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (bn1): Identity()\n",
       "      (conv2): ConvBn2d(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (float_functional): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): QuantizableBasicBlock(\n",
       "      (conv1): ConvBn2d(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (bn1): Identity()\n",
       "      (conv2): ConvBn2d(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (shortcut): Sequential()\n",
       "      (float_functional): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The model has to be switched to training mode before any layer fusion.\n",
    "# Otherwise the quantization aware training will not work correctly.\n",
    "model.train()\n",
    "fused_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuantizableResNet(\n",
       "  (conv1): ConvBnReLU2d(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (bn1): Identity()\n",
       "  (relu): Identity()\n",
       "  (layer1): Sequential(\n",
       "    (0): QuantizableBasicBlock(\n",
       "      (conv1): ConvBn2d(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (bn1): Identity()\n",
       "      (conv2): ConvBn2d(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (shortcut): Sequential()\n",
       "      (float_functional): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): QuantizableBasicBlock(\n",
       "      (conv1): ConvBn2d(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (bn1): Identity()\n",
       "      (conv2): ConvBn2d(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (shortcut): Sequential()\n",
       "      (float_functional): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): QuantizableBasicBlock(\n",
       "      (conv1): ConvBn2d(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (bn1): Identity()\n",
       "      (conv2): ConvBn2d(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (float_functional): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): QuantizableBasicBlock(\n",
       "      (conv1): ConvBn2d(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (bn1): Identity()\n",
       "      (conv2): ConvBn2d(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (shortcut): Sequential()\n",
       "      (float_functional): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): QuantizableBasicBlock(\n",
       "      (conv1): ConvBn2d(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (bn1): Identity()\n",
       "      (conv2): ConvBn2d(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (float_functional): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): QuantizableBasicBlock(\n",
       "      (conv1): ConvBn2d(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (bn1): Identity()\n",
       "      (conv2): ConvBn2d(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (shortcut): Sequential()\n",
       "      (float_functional): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): QuantizableBasicBlock(\n",
       "      (conv1): ConvBn2d(\n",
       "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (bn1): Identity()\n",
       "      (conv2): ConvBn2d(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (float_functional): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): QuantizableBasicBlock(\n",
       "      (conv1): ConvBn2d(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (bn1): Identity()\n",
       "      (conv2): ConvBn2d(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (bn2): Identity()\n",
       "      (shortcut): Sequential()\n",
       "      (float_functional): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ④ 모델을 평가 모드로 변환 후 (model.eval()) layer fusion이 잘 적용되었는 지 확인합니다. 확인 후에는 다시 학습 모드로 변경해 줍니다.\n",
    "# Model and fused model should be equivalent.\n",
    "model.eval()\n",
    "fused_model.eval()\n",
    "# assert model_equivalence(model_1=model, model_2=fused_model, device=cpu_device, rtol=1e-03, atol=1e-06, num_tests=100, input_size=(1,3,32,32)), \"Fused model is not equivalent to the original model!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuantizedResNet18(\n",
       "  (quant): QuantStub()\n",
       "  (dequant): DeQuantStub()\n",
       "  (model_fp32): QuantizableResNet(\n",
       "    (conv1): ConvBnReLU2d(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (bn1): Identity()\n",
       "    (relu): Identity()\n",
       "    (layer1): Sequential(\n",
       "      (0): QuantizableBasicBlock(\n",
       "        (conv1): ConvBn2d(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (bn1): Identity()\n",
       "        (conv2): ConvBn2d(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (bn2): Identity()\n",
       "        (shortcut): Sequential()\n",
       "        (float_functional): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): QuantizableBasicBlock(\n",
       "        (conv1): ConvBn2d(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (bn1): Identity()\n",
       "        (conv2): ConvBn2d(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (bn2): Identity()\n",
       "        (shortcut): Sequential()\n",
       "        (float_functional): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): QuantizableBasicBlock(\n",
       "        (conv1): ConvBn2d(\n",
       "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (bn1): Identity()\n",
       "        (conv2): ConvBn2d(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (bn2): Identity()\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (float_functional): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): QuantizableBasicBlock(\n",
       "        (conv1): ConvBn2d(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (bn1): Identity()\n",
       "        (conv2): ConvBn2d(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (bn2): Identity()\n",
       "        (shortcut): Sequential()\n",
       "        (float_functional): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): QuantizableBasicBlock(\n",
       "        (conv1): ConvBn2d(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (bn1): Identity()\n",
       "        (conv2): ConvBn2d(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (bn2): Identity()\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (float_functional): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): QuantizableBasicBlock(\n",
       "        (conv1): ConvBn2d(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (bn1): Identity()\n",
       "        (conv2): ConvBn2d(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (bn2): Identity()\n",
       "        (shortcut): Sequential()\n",
       "        (float_functional): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): QuantizableBasicBlock(\n",
       "        (conv1): ConvBn2d(\n",
       "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (bn1): Identity()\n",
       "        (conv2): ConvBn2d(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (bn2): Identity()\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (float_functional): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): QuantizableBasicBlock(\n",
       "        (conv1): ConvBn2d(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (bn1): Identity()\n",
       "        (conv2): ConvBn2d(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (bn2): Identity()\n",
       "        (shortcut): Sequential()\n",
       "        (float_functional): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (linear): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantized_model = QuantizedResNet18(model_fp32=fused_model)\n",
    "quantized_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_model.qconfig = torch.ao.quantization.get_default_qconfig(\"fbgemm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training QAT Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\devLupin\\Miniconda3\\envs\\qat\\lib\\site-packages\\torch\\ao\\quantization\\observer.py:214: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# https://pytorch.org/docs/stable/_modules/torch/quantization/quantize.html#prepare_qat\n",
    "quantized_model.train()\n",
    "quantized_model = torch.ao.quantization.prepare_qat(quantized_model)\n",
    "\n",
    "# ⑧ 모델을 다시 CUDA가 상태로 적용하고 CUDA를 이용하여 QAT를 모델 학습을 진행합니다.\n",
    "print(\"Training QAT Model...\")\n",
    "# quantized_model = train_model(model=quantized_model, train_loader=train_loader, test_loader=test_loader, device=cuda_device, learning_rate=1e-3, num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\devLupin\\Miniconda3\\envs\\qat\\lib\\site-packages\\torch\\ao\\quantization\\observer.py:1204: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ⑨ 모델을 다시 CPU 상태로 두고 QAT가 적용된 floating point 모델을 quantized integer model로 변환합니다.    \n",
    "quantized_model.to(cpu_device)\n",
    "\n",
    "# ⑪ quantized integer model을 저장합니다.\n",
    "quantized_model.eval()\n",
    "quantized_model = torch.ao.quantization.convert(quantized_model)\n",
    "\n",
    "save_torchscript_model(model=quantized_model, model_dir=model_dir, model_filename=quantized_model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_jit_model = load_torchscript_model(model_filepath=quantized_model_filepath, device=cpu_device)\n",
    "\n",
    "# _, fp32_eval_accuracy = evaluate_model(model=model, test_loader=test_loader, device=cpu_device, criterion=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RecursiveScriptModule(\n",
      "  original_name=QuantizedResNet18\n",
      "  (quant): RecursiveScriptModule(original_name=Quantize)\n",
      "  (dequant): RecursiveScriptModule(original_name=DeQuantize)\n",
      "  (model_fp32): RecursiveScriptModule(\n",
      "    original_name=QuantizableResNet\n",
      "    (conv1): RecursiveScriptModule(original_name=ConvReLU2d)\n",
      "    (bn1): RecursiveScriptModule(original_name=Identity)\n",
      "    (relu): RecursiveScriptModule(original_name=Identity)\n",
      "    (layer1): RecursiveScriptModule(\n",
      "      original_name=Sequential\n",
      "      (0): RecursiveScriptModule(\n",
      "        original_name=QuantizableBasicBlock\n",
      "        (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
      "        (bn1): RecursiveScriptModule(original_name=Identity)\n",
      "        (conv2): RecursiveScriptModule(original_name=Conv2d)\n",
      "        (bn2): RecursiveScriptModule(original_name=Identity)\n",
      "        (shortcut): RecursiveScriptModule(original_name=Sequential)\n",
      "        (float_functional): RecursiveScriptModule(\n",
      "          original_name=QFunctional\n",
      "          (activation_post_process): RecursiveScriptModule(original_name=Identity)\n",
      "        )\n",
      "      )\n",
      "      (1): RecursiveScriptModule(\n",
      "        original_name=QuantizableBasicBlock\n",
      "        (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
      "        (bn1): RecursiveScriptModule(original_name=Identity)\n",
      "        (conv2): RecursiveScriptModule(original_name=Conv2d)\n",
      "        (bn2): RecursiveScriptModule(original_name=Identity)\n",
      "        (shortcut): RecursiveScriptModule(original_name=Sequential)\n",
      "        (float_functional): RecursiveScriptModule(\n",
      "          original_name=QFunctional\n",
      "          (activation_post_process): RecursiveScriptModule(original_name=Identity)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (layer2): RecursiveScriptModule(\n",
      "      original_name=Sequential\n",
      "      (0): RecursiveScriptModule(\n",
      "        original_name=QuantizableBasicBlock\n",
      "        (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
      "        (bn1): RecursiveScriptModule(original_name=Identity)\n",
      "        (conv2): RecursiveScriptModule(original_name=Conv2d)\n",
      "        (bn2): RecursiveScriptModule(original_name=Identity)\n",
      "        (shortcut): RecursiveScriptModule(\n",
      "          original_name=Sequential\n",
      "          (0): RecursiveScriptModule(original_name=Conv2d)\n",
      "          (1): RecursiveScriptModule(original_name=BatchNorm2d)\n",
      "        )\n",
      "        (float_functional): RecursiveScriptModule(\n",
      "          original_name=QFunctional\n",
      "          (activation_post_process): RecursiveScriptModule(original_name=Identity)\n",
      "        )\n",
      "      )\n",
      "      (1): RecursiveScriptModule(\n",
      "        original_name=QuantizableBasicBlock\n",
      "        (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
      "        (bn1): RecursiveScriptModule(original_name=Identity)\n",
      "        (conv2): RecursiveScriptModule(original_name=Conv2d)\n",
      "        (bn2): RecursiveScriptModule(original_name=Identity)\n",
      "        (shortcut): RecursiveScriptModule(original_name=Sequential)\n",
      "        (float_functional): RecursiveScriptModule(\n",
      "          original_name=QFunctional\n",
      "          (activation_post_process): RecursiveScriptModule(original_name=Identity)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (layer3): RecursiveScriptModule(\n",
      "      original_name=Sequential\n",
      "      (0): RecursiveScriptModule(\n",
      "        original_name=QuantizableBasicBlock\n",
      "        (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
      "        (bn1): RecursiveScriptModule(original_name=Identity)\n",
      "        (conv2): RecursiveScriptModule(original_name=Conv2d)\n",
      "        (bn2): RecursiveScriptModule(original_name=Identity)\n",
      "        (shortcut): RecursiveScriptModule(\n",
      "          original_name=Sequential\n",
      "          (0): RecursiveScriptModule(original_name=Conv2d)\n",
      "          (1): RecursiveScriptModule(original_name=BatchNorm2d)\n",
      "        )\n",
      "        (float_functional): RecursiveScriptModule(\n",
      "          original_name=QFunctional\n",
      "          (activation_post_process): RecursiveScriptModule(original_name=Identity)\n",
      "        )\n",
      "      )\n",
      "      (1): RecursiveScriptModule(\n",
      "        original_name=QuantizableBasicBlock\n",
      "        (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
      "        (bn1): RecursiveScriptModule(original_name=Identity)\n",
      "        (conv2): RecursiveScriptModule(original_name=Conv2d)\n",
      "        (bn2): RecursiveScriptModule(original_name=Identity)\n",
      "        (shortcut): RecursiveScriptModule(original_name=Sequential)\n",
      "        (float_functional): RecursiveScriptModule(\n",
      "          original_name=QFunctional\n",
      "          (activation_post_process): RecursiveScriptModule(original_name=Identity)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (layer4): RecursiveScriptModule(\n",
      "      original_name=Sequential\n",
      "      (0): RecursiveScriptModule(\n",
      "        original_name=QuantizableBasicBlock\n",
      "        (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
      "        (bn1): RecursiveScriptModule(original_name=Identity)\n",
      "        (conv2): RecursiveScriptModule(original_name=Conv2d)\n",
      "        (bn2): RecursiveScriptModule(original_name=Identity)\n",
      "        (shortcut): RecursiveScriptModule(\n",
      "          original_name=Sequential\n",
      "          (0): RecursiveScriptModule(original_name=Conv2d)\n",
      "          (1): RecursiveScriptModule(original_name=BatchNorm2d)\n",
      "        )\n",
      "        (float_functional): RecursiveScriptModule(\n",
      "          original_name=QFunctional\n",
      "          (activation_post_process): RecursiveScriptModule(original_name=Identity)\n",
      "        )\n",
      "      )\n",
      "      (1): RecursiveScriptModule(\n",
      "        original_name=QuantizableBasicBlock\n",
      "        (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
      "        (bn1): RecursiveScriptModule(original_name=Identity)\n",
      "        (conv2): RecursiveScriptModule(original_name=Conv2d)\n",
      "        (bn2): RecursiveScriptModule(original_name=Identity)\n",
      "        (shortcut): RecursiveScriptModule(original_name=Sequential)\n",
      "        (float_functional): RecursiveScriptModule(\n",
      "          original_name=QFunctional\n",
      "          (activation_post_process): RecursiveScriptModule(original_name=Identity)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (linear): RecursiveScriptModule(\n",
      "      original_name=Linear\n",
      "      (_packed_params): RecursiveScriptModule(original_name=LinearPackedParams)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(quantized_jit_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[256, 64, 32, 32] [256, 64, 32, 32]\n",
      "[256, 64, 32, 32] [256, 64, 32, 32]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript, serialized code (most recent call last):\n  File \"code/__torch__.py\", line 14, in forward\n    x0 = (quant).forward(x, )\n    model_fp32 = self.model_fp32\n    x1 = (model_fp32).forward(x0, )\n          ~~~~~~~~~~~~~~~~~~~ <--- HERE\n    dequant = self.dequant\n    return (dequant).forward(x1, )\n  File \"code/__torch__/ResNet2D.py\", line 25, in forward\n    out0 = (layer1).forward(out, )\n    layer2 = self.layer2\n    out1 = (layer2).forward(out0, )\n            ~~~~~~~~~~~~~~~ <--- HERE\n    layer3 = self.layer3\n    out2 = (layer3).forward(out1, )\n  File \"code/__torch__/torch/nn/modules/container/___torch_mangle_3.py\", line 12, in forward\n    _0 = getattr(self, \"0\")\n    _1 = getattr(self, \"1\")\n    input0 = (_0).forward(input, )\n              ~~~~~~~~~~~ <--- HERE\n    return (_1).forward(input0, )\n  def __len__(self: __torch__.torch.nn.modules.container.___torch_mangle_3.Sequential) -> int:\n  File \"code/__torch__/ResNet2D/___torch_mangle_2.py\", line 22, in forward\n    out0 = (bn2).forward((conv2).forward(out, ), )\n    shortcut = self.shortcut\n    tmp = (shortcut).forward(x, )\n           ~~~~~~~~~~~~~~~~~ <--- HERE\n    print(torch.size(out0), torch.size(tmp))\n    float_functional = self.float_functional\n  File \"code/__torch__/torch/nn/modules/container/___torch_mangle_1.py\", line 13, in forward\n    _1 = getattr(self, \"1\")\n    input0 = (_0).forward(input, )\n    return (_1).forward(input0, )\n            ~~~~~~~~~~~ <--- HERE\n  def __len__(self: __torch__.torch.nn.modules.container.___torch_mangle_1.Sequential) -> int:\n    return 2\n  File \"code/__torch__/torch/ao/nn/quantized/modules/batchnorm.py\", line 26, in forward\n    scale = self.scale\n    zero_point = self.zero_point\n    _0 = ops.quantized.batch_norm2d(input, weight, bias, running_mean, running_var, 1.0000000000000001e-05, annotate(float, scale), annotate(int, zero_point))\n                                                                                                            ~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n    return _0\n\nTraceback of TorchScript, original code (most recent call last):\n  File \"C:\\Users\\devLupin\\AppData\\Local\\Temp\\ipykernel_3416\\3070739321.py\", line 29, in forward\n        # point to quantized in the quantized model\n        x = self.quant(x)\n        x = self.model_fp32(x)\n            ~~~~~~~~~~~~~~~ <--- HERE\n        # manually specify where tensors will be converted from quantized\n        # to floating point in the quantized model\n  File \"c:\\Users\\devLupin\\Desktop\\torch-quantization\\ResNet2D.py\", line 116, in forward\n        out = self.relu(self.bn1(self.conv1(x)))\n        out = self.layer1(out)\n        out = self.layer2(out)\n              ~~~~~~~~~~~ <--- HERE\n        out = self.layer3(out)\n        out = self.layer4(out)\n  File \"c:\\Users\\devLupin\\Miniconda3\\envs\\qat\\lib\\site-packages\\torch\\nn\\modules\\container.py\", line 204, in forward\n    def forward(self, input):\n        for module in self:\n            input = module(input)\n                    ~~~~~~ <--- HERE\n        return input\n  File \"c:\\Users\\devLupin\\Desktop\\torch-quantization\\ResNet2D.py\", line 86, in forward\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        tmp = self.shortcut(x)\n              ~~~~~~~~~~~~~ <--- HERE\n        print(out.shape, tmp.shape)\n    \n  File \"c:\\Users\\devLupin\\Miniconda3\\envs\\qat\\lib\\site-packages\\torch\\nn\\modules\\container.py\", line 204, in forward\n    def forward(self, input):\n        for module in self:\n            input = module(input)\n                    ~~~~~~ <--- HERE\n        return input\n  File \"c:\\Users\\devLupin\\Miniconda3\\envs\\qat\\lib\\site-packages\\torch\\ao\\nn\\quantized\\modules\\batchnorm.py\", line 65, in forward\n        # disabling this since this is not symbolically traceable\n        # self._check_input_dim(input)\n        return torch.ops.quantized.batch_norm2d(\n               ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n            input, self.weight, self.bias, self.running_mean,\n            self.running_var, self.eps, self.scale, self.zero_point)\nRuntimeError: Cannot input a tensor of dimension other than 0 as a scalar argument\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\devLupin\\Desktop\\torch-quantization\\QAT.ipynb Cell 24\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/devLupin/Desktop/torch-quantization/QAT.ipynb#X66sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m _, int8_eval_accuracy \u001b[39m=\u001b[39m evaluate_model(model\u001b[39m=\u001b[39;49mquantized_jit_model, test_loader\u001b[39m=\u001b[39;49mtest_loader, device\u001b[39m=\u001b[39;49mcpu_device, criterion\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n",
      "\u001b[1;32mc:\\Users\\devLupin\\Desktop\\torch-quantization\\QAT.ipynb Cell 24\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/devLupin/Desktop/torch-quantization/QAT.ipynb#X66sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m inputs \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/devLupin/Desktop/torch-quantization/QAT.ipynb#X66sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/devLupin/Desktop/torch-quantization/QAT.ipynb#X66sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(inputs)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/devLupin/Desktop/torch-quantization/QAT.ipynb#X66sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m _, preds \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(outputs, \u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/devLupin/Desktop/torch-quantization/QAT.ipynb#X66sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mif\u001b[39;00m criterion \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\devLupin\\Miniconda3\\envs\\qat\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript, serialized code (most recent call last):\n  File \"code/__torch__.py\", line 14, in forward\n    x0 = (quant).forward(x, )\n    model_fp32 = self.model_fp32\n    x1 = (model_fp32).forward(x0, )\n          ~~~~~~~~~~~~~~~~~~~ <--- HERE\n    dequant = self.dequant\n    return (dequant).forward(x1, )\n  File \"code/__torch__/ResNet2D.py\", line 25, in forward\n    out0 = (layer1).forward(out, )\n    layer2 = self.layer2\n    out1 = (layer2).forward(out0, )\n            ~~~~~~~~~~~~~~~ <--- HERE\n    layer3 = self.layer3\n    out2 = (layer3).forward(out1, )\n  File \"code/__torch__/torch/nn/modules/container/___torch_mangle_3.py\", line 12, in forward\n    _0 = getattr(self, \"0\")\n    _1 = getattr(self, \"1\")\n    input0 = (_0).forward(input, )\n              ~~~~~~~~~~~ <--- HERE\n    return (_1).forward(input0, )\n  def __len__(self: __torch__.torch.nn.modules.container.___torch_mangle_3.Sequential) -> int:\n  File \"code/__torch__/ResNet2D/___torch_mangle_2.py\", line 22, in forward\n    out0 = (bn2).forward((conv2).forward(out, ), )\n    shortcut = self.shortcut\n    tmp = (shortcut).forward(x, )\n           ~~~~~~~~~~~~~~~~~ <--- HERE\n    print(torch.size(out0), torch.size(tmp))\n    float_functional = self.float_functional\n  File \"code/__torch__/torch/nn/modules/container/___torch_mangle_1.py\", line 13, in forward\n    _1 = getattr(self, \"1\")\n    input0 = (_0).forward(input, )\n    return (_1).forward(input0, )\n            ~~~~~~~~~~~ <--- HERE\n  def __len__(self: __torch__.torch.nn.modules.container.___torch_mangle_1.Sequential) -> int:\n    return 2\n  File \"code/__torch__/torch/ao/nn/quantized/modules/batchnorm.py\", line 26, in forward\n    scale = self.scale\n    zero_point = self.zero_point\n    _0 = ops.quantized.batch_norm2d(input, weight, bias, running_mean, running_var, 1.0000000000000001e-05, annotate(float, scale), annotate(int, zero_point))\n                                                                                                            ~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n    return _0\n\nTraceback of TorchScript, original code (most recent call last):\n  File \"C:\\Users\\devLupin\\AppData\\Local\\Temp\\ipykernel_3416\\3070739321.py\", line 29, in forward\n        # point to quantized in the quantized model\n        x = self.quant(x)\n        x = self.model_fp32(x)\n            ~~~~~~~~~~~~~~~ <--- HERE\n        # manually specify where tensors will be converted from quantized\n        # to floating point in the quantized model\n  File \"c:\\Users\\devLupin\\Desktop\\torch-quantization\\ResNet2D.py\", line 116, in forward\n        out = self.relu(self.bn1(self.conv1(x)))\n        out = self.layer1(out)\n        out = self.layer2(out)\n              ~~~~~~~~~~~ <--- HERE\n        out = self.layer3(out)\n        out = self.layer4(out)\n  File \"c:\\Users\\devLupin\\Miniconda3\\envs\\qat\\lib\\site-packages\\torch\\nn\\modules\\container.py\", line 204, in forward\n    def forward(self, input):\n        for module in self:\n            input = module(input)\n                    ~~~~~~ <--- HERE\n        return input\n  File \"c:\\Users\\devLupin\\Desktop\\torch-quantization\\ResNet2D.py\", line 86, in forward\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        tmp = self.shortcut(x)\n              ~~~~~~~~~~~~~ <--- HERE\n        print(out.shape, tmp.shape)\n    \n  File \"c:\\Users\\devLupin\\Miniconda3\\envs\\qat\\lib\\site-packages\\torch\\nn\\modules\\container.py\", line 204, in forward\n    def forward(self, input):\n        for module in self:\n            input = module(input)\n                    ~~~~~~ <--- HERE\n        return input\n  File \"c:\\Users\\devLupin\\Miniconda3\\envs\\qat\\lib\\site-packages\\torch\\ao\\nn\\quantized\\modules\\batchnorm.py\", line 65, in forward\n        # disabling this since this is not symbolically traceable\n        # self._check_input_dim(input)\n        return torch.ops.quantized.batch_norm2d(\n               ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n            input, self.weight, self.bias, self.running_mean,\n            self.running_var, self.eps, self.scale, self.zero_point)\nRuntimeError: Cannot input a tensor of dimension other than 0 as a scalar argument\n"
     ]
    }
   ],
   "source": [
    "_, int8_eval_accuracy = evaluate_model(model=quantized_jit_model, test_loader=test_loader, device=cpu_device, criterion=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip this assertion since the values might deviate a lot.\n",
    "# assert model_equivalence(model_1=model, model_2=quantized_jit_model, device=cpu_device, rtol=1e-01, atol=1e-02, num_tests=100, input_size=(1,3,32,32)), \"Quantized model deviates from the original model too much!\"\n",
    "\n",
    "print(\"FP32 evaluation accuracy: {:.3f}\".format(fp32_eval_accuracy))\n",
    "print(\"INT8 evaluation accuracy: {:.3f}\".format(int8_eval_accuracy))\n",
    "\n",
    "fp32_cpu_inference_latency = measure_inference_latency(model=model, device=cpu_device, input_size=(1,3,32,32), num_samples=100)\n",
    "int8_cpu_inference_latency = measure_inference_latency(model=quantized_model, device=cpu_device, input_size=(1,3,32,32), num_samples=100)\n",
    "int8_jit_cpu_inference_latency = measure_inference_latency(model=quantized_jit_model, device=cpu_device, input_size=(1,3,32,32), num_samples=100)\n",
    "fp32_gpu_inference_latency = measure_inference_latency(model=model, device=cuda_device, input_size=(1,3,32,32), num_samples=100)\n",
    "\n",
    "print(\"FP32 CPU Inference Latency: {:.2f} ms / sample\".format(fp32_cpu_inference_latency * 1000))\n",
    "print(\"FP32 CUDA Inference Latency: {:.2f} ms / sample\".format(fp32_gpu_inference_latency * 1000))\n",
    "print(\"INT8 CPU Inference Latency: {:.2f} ms / sample\".format(int8_cpu_inference_latency * 1000))\n",
    "print(\"INT8 JIT CPU Inference Latency: {:.2f} ms / sample\".format(int8_jit_cpu_inference_latency * 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## library version issue\n",
    "\n",
    "- https://discuss.pytorch.org/t/torch-tensor-returns-error-while-creating-a-copy/103510\n",
    "- https://github.com/pytorch/pytorch/issues/76726\n",
    "- 버그가 수정되지 않을 것이라고 함.\n",
    "  - 현재 새로운 컴파일러 스택으로 이동하고 있고, Torchscript는 현재 유지 관리 상태"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
